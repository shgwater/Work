---
title: 2020-3-4 Hadoop学习
tags: 新建,模板,小书匠
grammar_cjkRuby: true
---


# 创建虚拟机
## 用户名及密码

- root
- rootroot

## hadoop环境配置

### 安装系统及hadoop

依据博客进行  https://www.cnblogs.com/xzjf/p/7231519.html

### 遇到的问题

#### 使用2.6.5的hadoop安装包时报错。
``` 
20/03/10 01:04:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
```

解决办法，重新下载2.7.7的安装包，重新安装之后可以正常使用，但是还是报错。但是此时不营销使用。


### 安装2.7.7 之后启动报错

 core-site.xml:1:1: Content is not allowed in prolog
 
 ## hadoop 的一些认识。
 
 ### hdfs 是什么
 
 HDFS 是 Hadoop 的分布式文件系统的简称。
 在 HDFS 目录下，没有对默认的数据库 default 创建文件夹。如果某张表属于 default 数据库，直接在数据仓库目录下创建一个文件夹。
 
 ## hive
 
 ### 安装hive
 
 见 大数据技术之HIVE.doc 。
 
 ### hive的基本操作
  
``` python

# 1. 启动hive
[root@hadoop102 hive]$ bin/hive
# 2. 查看数据库
hive>show databases;
# 3. 打开默认数据库
hive>use default;
# 4. 显示default数据库中的表
hive>show tables;
# 5. 创建一张表
hive> create table student(id int, name string) ;
# 6. 显示数据库中有几张表
hive>show tables;
# 7. 查看表的结构
hive>desc student;
# 8. 向表中插入数据
hive> insert into student values(1000,"ss");
# 9. 查询表中数据
hive> select * from student;
# 1. ）退出hive
hive> quit;

```

### 将本地文件导入 Hive 案例

- 需求 将本地目录下的txt文件导入hive中的表中。结构为student(id int, name string)

1. 创建测试txt数据，注意两列数据中间的分隔符为 tab。
2. 在hive中创建表结构。
``` python
show databases;
use default;
show tables;
desc student;
# 创建表并且声明文件分隔符 '\t' 。
create table student(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
# 加载txt数据到表中
load data local inpath '/home/hadoop/datas/student.txt' into table student;

select * from student;

```
