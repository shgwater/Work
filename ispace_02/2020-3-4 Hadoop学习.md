---
title: 2020-3-4 Hadoop学习
tags: 新建,模板,小书匠
grammar_cjkRuby: true
---


# 创建虚拟机
## 用户名及密码

- root
- rootroot

## hadoop环境配置

### 安装系统及hadoop

依据博客进行  https://www.cnblogs.com/xzjf/p/7231519.html

### 遇到的问题

#### 使用2.6.5的hadoop安装包时报错。
``` 
20/03/10 01:04:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
```

解决办法，重新下载2.7.7的安装包，重新安装之后可以正常使用，但是还是报错。但是此时不营销使用。


### 安装2.7.7 之后启动报错

 core-site.xml:1:1: Content is not allowed in prolog
 
 ### 安装完成之后启动
 
 [hadoop@Master hadoop]$ ./sbin/start-dfs.sh
[hadoop@Master hadoop]$ ./sbin/start-yarn.sh

启动之后再启动hive。
 
 ## hadoop 的一些认识。
 
 ### hdfs 是什么
 
 HDFS 是 Hadoop 的分布式文件系统的简称。
 在 HDFS 目录下，没有对默认的数据库 default 创建文件夹。如果某张表属于 default 数据库，直接在数据仓库目录下创建一个文件夹。
 与linux自带的文件系统不同的另外一套文件系统，需要使用程序读取。
 
 ### hdfs 常用操作
 ``` python
 # 查看 hdfs 的目录结构
 
[hadoop@Master hadoop]$ ./bin/hdfs dfs -ls /user/hive/
[hadoop@Master hadoop]$ ./bin/hadoop fs -ls /

# 递归结构显示文件目录 -ls -R

[hadoop@Master hadoop]$ ./bin/hadoop fs -ls -R /

# 创建目录

[hadoop@Master hadoop]$ ./bin/hadoop fs -mkdir /user/hive/test

# hadoop fs -rm   删除文件，-rm -R 递归删除目录和文件

 [hadoop@Master hadoop]$ ./bin/hadoop fs -rm -R /user/hive/test
 
 # hadoop fs -put  [localsrc] [dst]  从本地加载文件到HDFS
 
 [hadoop@Master hadoop]$ ./bin/hadoop fs -put test.txt /user/hive/test
 
	 # 加载/opt/module/datas/student.txt 文件到student数据库表中。
 
	hive> load data local inpath '/opt/module/datas/student.txt' into table student;
	
# hadoop fs -get  [dst] [localsrc]  从HDFS导出文件到本地

 [hadoop@Master hadoop]$ ./bin/hadoop fs -get /user/hive/test/test.txt


 
 ```
 
 ## hive
 
 ### 安装hive
 
 见 大数据技术之HIVE.doc 。
 
 ### hive的基本操作
  
``` python

# 1. 启动hive
[root@hadoop102 hive]$ bin/hive
# 2. 查看数据库
hive>show databases;
# 3. 打开默认数据库
hive>use default;
# 4. 显示default数据库中的表
hive>show tables;
# 5. 创建一张表
hive> create table student(id int, name string) ;
# 6. 显示数据库中有几张表
hive>show tables;
# 7. 查看表的结构
hive>desc student;
# 8. 向表中插入数据
hive> insert into student values(1000,"ss");
# 9. 查询表中数据
hive> select * from student;
# 1. ）退出hive
hive> quit;

```

### 将本地文件导入 Hive 案例

- 需求 将本地目录下的txt文件导入hive中的表中。结构为student(id int, name string)

1. 创建测试txt数据，注意两列数据中间的分隔符为 tab。
2. 在hive中创建表结构。
``` python
show databases;
use default;
show tables;
desc student;
# 创建表并且声明文件分隔符 '\t' 。
create table student(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
# 加载txt数据到表中
load data local inpath '/home/hadoop/datas/student.txt' into table student;

select * from student;

```
